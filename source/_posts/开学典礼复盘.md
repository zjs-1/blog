---
layout: title
title: 开学典礼复盘
date: 2019-3-20 10:19:36
tags: [复盘总结]
categories: 技术
---

## 背景

CPA开学典礼是每年CPA开的第一节课，面向所有CPA学员和非学员。因为是开学第一堂课，学生积极性会比较高，而且运营也会做一系列推广。所以在过去两年，系统都在开学典礼时由于较高的并发出现短时间的崩溃。

> 17年官网PV/UV百度统计

![](http://cdn.jsblog.site/15529109429491.jpg)

> 18年官网PV/UV百度统计

![](http://cdn.jsblog.site/15529111998745.jpg)

> 19年官网PV/UV百度统计

![](http://cdn.jsblog.site/15529111789398.jpg)

## 出现过的问题

17年的时候，主要是在功能方面出了比较多的问题，那个时候应该是刚对接完CC，第一次大批量面向学员，所以在直播间鉴权的地方出了问题(这里留了个大坑，那个时候去掉的鉴权到现在都没补上)，很多学员都进不去直播间。因为在功能方面出了问题，似乎就忽略了性能方面存在的隐患。

18年的时候，就崩得很清晰了。在开课前几天我们已经在对官网进行优化了，比如静态资源走cdn，研究各种缓存，那个时候已经有了改成前端渲染的想法，但是因为时间太短不可能做到。那个时候数据库已经上了读写分离了，官网也已经部署了2-3台服务器。但还是各种花式出问题：

1. mongodb因为官网连接数过多，挂了(php-fpm开多线程，链接并不是共享连接池的方式)
2. 官网存在很多慢查询语句，mysql由于读写分离，没有完全挂。但是因为官网是后端渲染的，数据查询响应慢，导致大量请求堆积，服务器CPU过高挂了。
2. mysql因为听课记录大批量写入，挂了(18年新增的业务，大家同时结束听课，往数据库写数据，这次读写分离也没用了)

最后就是各种排查，慢查询的都加上索引，该改的、能改的都改了，官网也增加服务器到了6台，数据库读写分离也加到了最多从库的上限。

## 改版

当时预估的是以三倍的速度增加，19年学员会翻三倍，网站性能至少也要翻三倍。这意味着如果依旧使用后端渲染的方式，19年我们至少要部署18台服务器供官网使用，而且那个时候这边还没有使用docker，每一台服务器都需要手动部署。

所以方向很明确，18年必须对官网进行改版，改版的方向就是将官网从`PHP + twig + jquery + bootstrap`后端渲染，改成用`node + vue`前端渲染，充分利用cdn缓存，释放服务器的压力，同时还希望改版能提升后续的开发效率。

虽然方向很明确，但并不是想好了就马上动手做，改版一直到18年10月才由辉辉和文豪启动。改版的路径是圈子 -> 课程页 -> 首页，其他页面优先级靠后(埋了一个坑)。

> 改版在19年年前就完成了第一期，改版的前端开发主要由辉辉和文豪完成，所以如果大家对里面的开发细节感兴趣，建议辉辉和文豪后面做个分享。
> 同时也是黑白提供了很多接口支持，改版才能顺利完成。不过有些接口还有改善的余地。

![](http://cdn.jsblog.site/15529154708596.jpg)


![](http://cdn.jsblog.site/15529153925589.jpg)

## 开课前准备

虽然已经做了改版，但我们还是对官网的实际承受能力没有信心，暴露了两个问题: 对系统的承受能力没办法量化; 对实际的访问量没有B数。

既然没办法定量，时间又有限，就只能用各种可能的方法来提高并发访问量了。

### 缓存

能想到的第一步就是缓存，由于大部分接口都与用户相关，所以在瞬时多用户高并发的情况下，这种缓存并没有多大作用。

因此只能从产品角度临时放弃掉首页的用户信息，比如课程的会员折扣价显示。然后由前端中间层直接做接口数据的缓存。

一开始的想法是做成多个线上代码版本，上课前临时做个切换。后来发现暴露一个接口作为缓存模式的开关比较方便。

> 副作用: 接口缓存是在中间层做的，会出现内容更新迟滞，而且从产品功能角度牺牲了用户的个性化数据。

### 公开课页面静态化

本来以为加了缓存就没什么问题了，结果在上课两天前，运营那边说开学典礼当晚要推送公开课页面。

因为公开课页面并没有列入一期的改版计划中，所以这个时候公开课页面还是后端渲染的，很可能承受不了推送带来的并发。

于是我们临时想了个办法，把对应的公开课课程页面保存成静态文件，去掉了跟用户相关的内容，由nginx直接做域名指向，配合上cdn，对服务器的压力几乎为0。

> 副作用: 由于是手动操作，所以只能对某几个课程做静态化；一些动态数据只能牺牲，比如观看人数统计；上课结束之后，还必须及时把页面撤下来换成动态页面，否则用户看不到回放。

## 直播当晚

![](http://cdn.jsblog.site/15529782029068.jpg)


![](http://cdn.jsblog.site/15529779236207.jpg)

该做的准备都做好了，直播当晚基本就没什么好弄的了，守在电脑前把缓存什么的都打开，就干盯着服务器监控和百度统计看。

最后当晚的直播并发人数最高差不多是5000多，比预估的少了挺多，但不管怎么说官网是hold住了没有崩，从各项服务器监控来看，实际可承受并发人数还可以更高。

## 事故

### 3.4

本来以为顺利渡过了开学典礼，后面的课都应该没什么问题了，结果开学典礼第二晚就被打脸了，当晚八点左右系统没有任何预兆就崩了。

简单的排查后问题定位在`任务服务`上，一开始以为是因为任务表太大(当时已经达到5千万条数据了)，如果是这个原因，短时间内是很难有根本性的解决方案了(拆表涉及到业务代码改动，一时半会弄不完)。所以只能做一些微乎其微的改进，比如将其中1千万条过期任务数据迁走。

-------  转折线   ------

第二天在排查代码的时候，发现了`任务服务`里有一段定时任务的代码(**问题: 定时任务没有统一管理**)，作用是找到所用过期的任务并将其清除。

![](http://cdn.jsblog.site/15529801887465.jpg)


UPDATE语句会走数据库主库，在数据量小的时候影响比较小(**问题: 只关注了业务完成，没有关注业务未来发展带来的性能问题**)，但是任务表已经到了千万级，所以整个语句执行会很久。而且为了应对这段时间的压力，任务服务增加到了8个实例，所以这个语句会在20:10的时候执行八次，数据库压力上升。加上八点上课的访问量，系统就崩了。

临时解决方案就是把定时任务的时间调开，副作用是任务过期可能不及时。

### 3.6

把任务服务安抚好后，又平安渡过了一晚，3.6那晚又开开心心地去吃饭，系统又崩了。

这次崩得也很清晰，当晚sheep进班进组推送，服务实例开得太少，并发稍微一高，服务器的CPU上升，同时该服务器又是docker swarm的leader，所以同时影响到了集群里的所有服务。

## 总结

从最终结果来看，官网改版在应对高并发上课这件事上已经产生了显著的效果，但是还是有很多东西待完善，不管是在前端还是后端都还有很长的路要走。

下一个关卡应该就是学期末的考试高峰了。


